{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f019c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- üìö Import Libraries ---\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d101f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ‚öôÔ∏è Configuration ---\n",
    "\n",
    "# Define the folder structure and directories to be processed\n",
    "\"\"\"\n",
    "üìÅ Required Folder Structure\n",
    "\n",
    "my_data_directory/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ human/\n",
    "‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ person1_standing_with_jacket/\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ signal_5000.csv\n",
    "‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ person1_sitting_with_jacket/\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ signal_5000.csv\n",
    "‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ... (more scenario folders for 'human')\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ nonhuman/\n",
    "    ‚îÇ\n",
    "    ‚îú‚îÄ‚îÄ chair_with_bag_and_jacket/\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ signal_5000.csv\n",
    "    ‚îÇ\n",
    "    ‚îú‚îÄ‚îÄ chair_without_bag/\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ signal_5000.csv\n",
    "    ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ ... (more scenario folders for 'nonhuman')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This should be the folder containing the 'human' and 'nonhuman' subdirectories.\n",
    "# We will use this data for testing our deep learning model.\n",
    "VAL_DATA_DIRECTORY = '/Users/anuragde/Documents/project-work/myvaldata' \n",
    "\n",
    "# Set the path where the preprocessed .npy files will be saved.\n",
    "OUTPUT_DIRECTORY = './preprocessed_val_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a896c288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Discovering Folders (Scenarios) ---\n",
      "\n",
      "Found 6 folders(scenarios) for 'human':\n",
      "  [person4_chair_sitting_with_jacket, person4_chair_sitting_without_jacket, person4_sitting_office_table_with_jacket, person4_sitting_office_table_without_jacket, person4_with_jacket_standing, person4_without_jacket_standing]\n",
      "\n",
      "Found 6 folders(scenarios) for 'nonhuman':\n",
      "  [chair_with_bag_and_jacket, drawer_with_basket, empty_chair, empty_floor, office_table_with_books_and_computer, office_table_with_laptop]\n",
      "\n",
      "‚úÖ Discovery complete. Found a total of 12 folders(scenarios).\n"
     ]
    }
   ],
   "source": [
    "# --- üìÇ Discover and List Folders ---\n",
    "\n",
    "scenarios_to_process = {}\n",
    "total_scenarios = 0\n",
    "\n",
    "print(\"--- Discovering Folders (Scenarios) ---\")\n",
    "\n",
    "if not os.path.isdir(VAL_DATA_DIRECTORY):\n",
    "    print(f\"‚ùå Error: The specified data directory does not exist: {VAL_DATA_DIRECTORY}\")\n",
    "else:\n",
    "    for category in ['human', 'nonhuman']:\n",
    "        category_path = os.path.join(VAL_DATA_DIRECTORY, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            # Find all subdirectories in the category folder\n",
    "            scenarios = [s for s in os.listdir(category_path) if os.path.isdir(os.path.join(category_path, s))]\n",
    "            scenarios.sort()  # Sort alphabetically for consistent order\n",
    "            scenarios_to_process[category] = scenarios\n",
    "            \n",
    "            # Print the discovered folders in a compact, single line\n",
    "            print(f\"\\nFound {len(scenarios)} folders(scenarios) for '{category}':\")\n",
    "            if scenarios:\n",
    "                print(f\"  [{', '.join(scenarios)}]\")\n",
    "            \n",
    "            total_scenarios += len(scenarios)\n",
    "        else:\n",
    "            print(f\"\\nWarning: Directory for category '{category}' not found.\")\n",
    "            scenarios_to_process[category] = []\n",
    "\n",
    "    print(f\"\\n‚úÖ Discovery complete. Found a total of {total_scenarios} folders(scenarios).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4c6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- üéõÔ∏è Preprocessing Function ---\n",
    "\n",
    "def process_and_save_spectrograms(data_path, output_path, scenarios_dict):\n",
    "    \"\"\"\n",
    "    A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. \n",
    "    In this script, it's generated using a Short-Time Fourier Transform (STFT), which breaks down the \n",
    "    process into several key steps.\n",
    "\n",
    "    ---\n",
    "\n",
    "    ### Step 1: Defining the STFT Parameters\n",
    "    - n_fft = 256 (Window Size): The signal is analyzed in overlapping chunks of 256 samples.\n",
    "    - hop_length = 128 (Step Size): The analysis window slides forward 128 samples at a time.\n",
    "    - window = torch.hann_window(n_fft): A Hann window is applied to each chunk to reduce artifacts.\n",
    "\n",
    "    ### Step 2: The STFT Calculation (`torch.stft`)\n",
    "    This function slides the window across the signal, computing a Fast Fourier Transform (FFT) on each chunk. \n",
    "    The output is a 2D array of complex numbers representing the frequency and phase information over time.\n",
    "\n",
    "    ### Step 3: Creating the Magnitude Spectrogram (`torch.abs`)\n",
    "    We take the absolute value of the complex numbers to get their magnitude, discarding the phase. \n",
    "    This final 2D array of real numbers is the spectrogram.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Preprocessing ---\")\n",
    "    \n",
    "    # --- FIXED PARAMETERS ---\n",
    "    FIXED_LENGTH = 19517\n",
    "    n_fft, hop_length = 256, 128\n",
    "    window = torch.hann_window(n_fft)\n",
    "    \n",
    "    all_spectrograms = []\n",
    "    all_labels = []\n",
    "\n",
    "    for category, label in [('human', 1), ('nonhuman', 0)]:\n",
    "        scenarios = scenarios_dict.get(category, [])\n",
    "        if not scenarios:\n",
    "            continue\n",
    "        \n",
    "        category_path = os.path.join(data_path, category)\n",
    "        \n",
    "        # This loop will now have a continuous progress bar\n",
    "        for scenario in tqdm(scenarios, desc=f\"Processing '{category}'\"):\n",
    "            scenario_path = os.path.join(category_path, scenario)\n",
    "            csv_file = next((f for f in os.listdir(scenario_path) if f.endswith('.csv')), None)\n",
    "            if not csv_file: continue\n",
    "\n",
    "            df = pd.read_csv(os.path.join(scenario_path, csv_file), header=None)\n",
    "            if df.empty: continue\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                if row.shape[0] <= 5500: continue\n",
    "                signal = row.values[5500:].astype(np.float32)\n",
    "\n",
    "                if signal.shape[0] > FIXED_LENGTH:\n",
    "                    signal = signal[:FIXED_LENGTH]\n",
    "                elif signal.shape[0] < FIXED_LENGTH:\n",
    "                    padding = np.zeros(FIXED_LENGTH - signal.shape[0], dtype=np.float32)\n",
    "                    signal = np.concatenate((signal, padding))\n",
    "                \n",
    "                signal_tensor = torch.from_numpy(signal)\n",
    "                spec = torch.stft(signal_tensor, n_fft=n_fft, hop_length=hop_length, window=window, return_complex=True)\n",
    "                spectrogram = torch.abs(spec)\n",
    "                \n",
    "                all_spectrograms.append(spectrogram.numpy())\n",
    "                all_labels.append(label)\n",
    "\n",
    "    print(\"\\n-> Stacking and saving data to .npy files...\")\n",
    "    if not all_spectrograms:\n",
    "        print(\"Error: No data was processed. Aborting save.\")\n",
    "        return\n",
    "\n",
    "    spectrograms_array = np.array(all_spectrograms, dtype=np.float32)\n",
    "    labels_array = np.array(all_labels, dtype=np.int64)\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    dataset_name = os.path.basename(os.path.normpath(data_path))\n",
    "    np.save(os.path.join(output_path, f'{dataset_name}_spectrograms.npy'), spectrograms_array)\n",
    "    np.save(os.path.join(output_path, f'{dataset_name}_labels.npy'), labels_array)\n",
    "    \n",
    "    print(f\"‚úÖ Preprocessing complete for {dataset_name}.\")\n",
    "    print(f\"   - Spectrograms saved to: {os.path.join(output_path, f'{dataset_name}_spectrograms.npy')} with shape {spectrograms_array.shape}\")\n",
    "    print(f\"   - Labels saved to:     {os.path.join(output_path, f'{dataset_name}_labels.npy')} with shape {labels_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e9dd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Preprocessing ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 'human': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:17<00:00,  2.89s/it]\n",
      "Processing 'nonhuman': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:16<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Stacking and saving data to .npy files...\n",
      "‚úÖ Preprocessing complete for myvaldata.\n",
      "   - Spectrograms saved to: ./preprocessed_val_data/myvaldata_spectrograms.npy with shape (12000, 129, 153)\n",
      "   - Labels saved to:     ./preprocessed_val_data/myvaldata_labels.npy with shape (12000,)\n"
     ]
    }
   ],
   "source": [
    "# --- ‚ñ∂Ô∏è Execute Processing ---\n",
    "\n",
    "if total_scenarios > 0:\n",
    "    # Pass the discovered folder list to the function\n",
    "    process_and_save_spectrograms(VAL_DATA_DIRECTORY, OUTPUT_DIRECTORY, scenarios_to_process)\n",
    "else:\n",
    "    print(\"No scenarios were found to process. Please check your VAL_DATA_DIRECTORY path.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
